#!/usr/bin/env python3
"""
ç»Ÿä¸€çš„ YFinance æ•°æ®è·å–å™¨

è¿™ä¸ªæ¨¡å—æä¾›äº†ç»Ÿä¸€çš„æ•°æ®è·å–æ¥å£ï¼ŒåŒ…å«ï¼š
- æ™ºèƒ½é€Ÿç‡é™åˆ¶
- ä¼šè¯ç®¡ç†å’Œä»£ç†æ”¯æŒ
- æ•°æ®ç¼“å­˜å’Œå¤ç”¨
- æ‰¹é‡è·å–ä¼˜åŒ–
- å¼ºåŒ–åæ£€æµ‹æœºåˆ¶
"""

import os
import time
import random
import threading
import hashlib
import uuid
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
import pandas as pd

import yfinance as yf
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# å°è¯•å¯¼å…¥ curl_cffi
try:
    from curl_cffi import requests as cf_requests
    CURL_CFFI_AVAILABLE = True
except ImportError:
    CURL_CFFI_AVAILABLE = False
    cf_requests = None

def generate_dynamic_user_agent():
    """ç”ŸæˆåŠ¨æ€User-Agentï¼ŒåŸºäºçœŸå®æµè§ˆå™¨æ¨¡å¼"""
    # æ—¶é—´æˆ³å’ŒéšæœºID
    timestamp = str(int(time.time()))
    random_id = str(uuid.uuid4())[:8]
    hash_suffix = hashlib.md5(f"{timestamp}-{random_id}".encode()).hexdigest()[:6]
    
    # æœ€æ–°Chromeç‰ˆæœ¬
    chrome_versions = [
        "119.0.0.0", "120.0.0.0", "121.0.0.0", "122.0.0.0", "123.0.0.0"
    ]
    chrome_version = random.choice(chrome_versions)
    
    # æ“ä½œç³»ç»Ÿé€‰æ‹©
    os_options = [
        "Windows NT 10.0; Win64; x64",
        "Macintosh; Intel Mac OS X 10_15_7",
        "X11; Linux x86_64"
    ]
    os_string = random.choice(os_options)
    
    # ç”Ÿæˆæ›´çœŸå®çš„User-Agent
    user_agents = [
        f"Mozilla/5.0 ({os_string}) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/{chrome_version} Safari/537.36",
        f"Mozilla/5.0 ({os_string}) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/{chrome_version} Safari/537.36 Edg/119.0.0.0",
        f"Mozilla/5.0 ({os_string}) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15"
    ]
    
    return random.choice(user_agents)

def get_enhanced_headers():
    """è·å–å¢å¼ºçš„æµè§ˆå™¨headersï¼Œå®Œå…¨æ¨¡æ‹ŸçœŸå®æµè§ˆå™¨"""
    return {
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
        'Accept-Encoding': 'gzip, deflate, br',
        'Accept-Language': 'en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7',
        'Cache-Control': 'max-age=0',
        'sec-ch-ua': '"Google Chrome";v="119", "Chromium";v="119", "Not?A_Brand";v="24"',
        'sec-ch-ua-mobile': '?0',
        'sec-ch-ua-platform': '"Linux"',
        'sec-fetch-dest': 'document',
        'sec-fetch-mode': 'navigate',
        'sec-fetch-site': 'none',
        'sec-fetch-user': '?1',
        'upgrade-insecure-requests': '1',
        'Connection': 'keep-alive',
        'DNT': '1',
        'Pragma': 'no-cache',
    }

@dataclass
class YFinanceDataset:
    """YFinance æ•°æ®é›†åˆ"""
    ticker: str
    info: Dict[str, Any]
    history: pd.DataFrame
    financials: pd.DataFrame
    balance_sheet: pd.DataFrame
    cashflow: pd.DataFrame
    quarterly_financials: pd.DataFrame
    quarterly_balance_sheet: pd.DataFrame
    quarterly_cashflow: pd.DataFrame
    income_stmt: pd.DataFrame
    quarterly_income_stmt: pd.DataFrame
    news: List[Dict[str, Any]]
    fetch_timestamp: float


# Global data cache (ç®€å•çš„å†…å­˜ç¼“å­˜)
_data_cache: Dict[str, YFinanceDataset] = {}
_cache_lock = threading.Lock()


def get_proxy_list():
    """è·å–ä»£ç†åˆ—è¡¨ï¼Œæ”¯æŒå¤šç§æ ¼å¼"""
    proxies = []
    
    # ä»ç¯å¢ƒå˜é‡è·å–ä»£ç†
    proxy_http = os.environ.get("YFINANCE_PROXY_HTTP", "")
    proxy_https = os.environ.get("YFINANCE_PROXY_HTTPS", "")
    
    # è§£æé€—å·åˆ†éš”çš„ä»£ç†åˆ—è¡¨
    if proxy_http:
        for proxy in proxy_http.split(','):
            proxy = proxy.strip()
            if proxy:
                proxies.append({'http': proxy, 'https': proxy})
    
    if proxy_https and proxy_https != proxy_http:
        for proxy in proxy_https.split(','):
            proxy = proxy.strip()
            if proxy:
                proxies.append({'http': proxy, 'https': proxy})
    
    return proxies

def create_yfinance_session():
    """Create a session with enhanced anti-detection features."""
    
    # åœ¨äº‘æœåŠ¡å™¨ç¯å¢ƒä¸‹å¼ºåˆ¶ä½¿ç”¨ä»£ç†
    use_proxy = True
    
    if CURL_CFFI_AVAILABLE:
        # ä½¿ç”¨curl_cffiï¼Œæ›´å¥½çš„åæ£€æµ‹èƒ½åŠ›
        session = cf_requests.Session()
        
        # è®¾ç½®åŠ¨æ€headers
        enhanced_headers = get_enhanced_headers()
        enhanced_headers['User-Agent'] = generate_dynamic_user_agent()
        session.headers.update(enhanced_headers)
        
        # ä»£ç†é…ç½®
        if use_proxy:
            proxy_list = get_proxy_list()
            if proxy_list:
                selected_proxy = random.choice(proxy_list)
                session.proxies = selected_proxy
                print(f"ğŸ”— Using proxy: {selected_proxy}")
            else:
                print("âš ï¸ No proxy available, using direct connection (may fail)")
        
        return session
    else:
        # Fallback to regular requests session
        session = requests.Session()
        
        # Retry strategy
        retry_strategy = Retry(
            total=3,
            backoff_factor=1,
            status_forcelist=[429, 500, 502, 503, 504],
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("http://", adapter)
        session.mount("https://", adapter)
        
        # è®¾ç½®åŠ¨æ€headers
        enhanced_headers = get_enhanced_headers()
        enhanced_headers['User-Agent'] = generate_dynamic_user_agent()
        session.headers.update(enhanced_headers)
        
        # ä»£ç†é…ç½®
        if use_proxy:
            proxy_list = get_proxy_list()
            if proxy_list:
                selected_proxy = random.choice(proxy_list)
                session.proxies.update(selected_proxy)
                print(f"ğŸ”— Using proxy: {selected_proxy}")
            else:
                print("âš ï¸ No proxy available, using direct connection (may fail)")
        
        return session

def safe_fetch_yfinance_data(ticker_symbol: str, max_retries: int = 5) -> Optional[YFinanceDataset]:
    """å®‰å…¨åœ°è·å– YFinance æ•°æ®ï¼Œå¢å¼ºé‡è¯•æœºåˆ¶"""
    
    for attempt in range(max_retries):
        try:
            
            # æ¯æ¬¡å°è¯•éƒ½ä½¿ç”¨æ–°çš„sessionå’Œä»£ç†
            session = create_yfinance_session()
            ticker = yf.Ticker(ticker_symbol, session=session)
            
            # è·å–æ‰€æœ‰éœ€è¦çš„æ•°æ®
            print(f"ğŸ”„ Fetching data for {ticker_symbol} (attempt {attempt + 1}/{max_retries})")
            
            # Get info and history
            info = ticker.info or {}
            
            # Get historical data (last 1 year)
            end_date = datetime.now()
            start_date = end_date - timedelta(days=365)
            history = ticker.history(start=start_date, end=end_date)
            
            # Get financial statements
            financials = ticker.financials
            balance_sheet = ticker.balance_sheet
            cashflow = ticker.cashflow
            quarterly_financials = ticker.quarterly_financials
            quarterly_balance_sheet = ticker.quarterly_balance_sheet
            quarterly_cashflow = ticker.quarterly_cashflow
            
            # Get income statements (same as financials for compatibility)
            income_stmt = financials  # alias
            quarterly_income_stmt = quarterly_financials  # alias
            
            # Get news
            try:
                news = ticker.news or []
            except:
                news = []
            
            # Create dataset
            dataset = YFinanceDataset(
                ticker=ticker_symbol,
                info=info,
                history=history,
                financials=financials,
                balance_sheet=balance_sheet,
                cashflow=cashflow,
                quarterly_financials=quarterly_financials,
                quarterly_balance_sheet=quarterly_balance_sheet,
                quarterly_cashflow=quarterly_cashflow,
                income_stmt=income_stmt,
                quarterly_income_stmt=quarterly_income_stmt,
                news=news,
                fetch_timestamp=time.time()
            )
            
            # æˆåŠŸåå¢åŠ éšæœºå»¶è¿Ÿ
            delay = random.uniform(1.0, 3.0)  # å¢åŠ å»¶è¿Ÿæ—¶é—´
            print(f"âœ… Successfully fetched {ticker_symbol}, waiting {delay:.1f}s...")
            time.sleep(delay)
            
            return dataset
            
        except Exception as e:
            error_msg = str(e).lower()
            print(f"âŒ Attempt {attempt + 1} failed for {ticker_symbol}: {str(e)}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯é€Ÿç‡é™åˆ¶é”™è¯¯
            if "too many requests" in error_msg or "rate limit" in error_msg:
                if attempt < max_retries - 1:
                    # é€Ÿç‡é™åˆ¶é”™è¯¯ï¼Œç­‰å¾…æ›´é•¿æ—¶é—´
                    wait_time = (30 * (attempt + 1)) + random.uniform(10, 30)
                    print(f"â³ Rate limited, waiting {wait_time:.1f} seconds before retry...")
                    time.sleep(wait_time)
                    continue
            
            if attempt < max_retries - 1:
                # å…¶ä»–é”™è¯¯ï¼ŒæŒ‡æ•°é€€é¿
                wait_time = (2 ** attempt) + random.uniform(5, 15)
                print(f"â³ Retrying in {wait_time:.1f} seconds...")
                time.sleep(wait_time)
            else:
                print(f"ğŸ’€ All attempts failed for {ticker_symbol}")
                return None
    
    return None

def get_yfinance_data(ticker: str, force_refresh: bool = False) -> Optional[YFinanceDataset]:
    """è·å– YFinance æ•°æ®ï¼Œå¸¦ç¼“å­˜
    
    Args:
        ticker: è‚¡ç¥¨ä»£ç 
        force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°ï¼ˆå¿½ç•¥ç¼“å­˜ï¼‰
        
    Returns:
        YFinance æ•°æ®é›†ï¼Œå¦‚æœå¤±è´¥è¿”å› None
    """
    with _cache_lock:
        # æ£€æŸ¥ç¼“å­˜
        if not force_refresh and ticker in _data_cache:
            cached_data = _data_cache[ticker]
            # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸï¼ˆ5åˆ†é’Ÿï¼‰
            if time.time() - cached_data.fetch_timestamp < 300:
                print(f"Using cached data for {ticker}")
                return cached_data
        
        # è·å–æ–°æ•°æ®
        print(f"Fetching fresh data for {ticker}")
        dataset = safe_fetch_yfinance_data(ticker)
        
        if dataset:
            # ç¼“å­˜æ•°æ®
            _data_cache[ticker] = dataset
            
        return dataset

def get_batch_yfinance_data(tickers: List[str], force_refresh: bool = False) -> Dict[str, YFinanceDataset]:
    """æ‰¹é‡è·å– YFinance æ•°æ®
    
    Args:
        tickers: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°
        
    Returns:
        ticker åˆ°æ•°æ®é›†çš„æ˜ å°„
    """
    results = {}
    
    for ticker in tickers:
        try:
            dataset = get_yfinance_data(ticker, force_refresh)
            if dataset:
                results[ticker] = dataset
        except Exception as e:
            print(f"Error fetching data for {ticker}: {str(e)}")
    
    return results

def clear_cache():
    """æ¸…é™¤ç¼“å­˜"""
    with _cache_lock:
        _data_cache.clear()
        print("YFinance data cache cleared")

def get_cache_status():
    """è·å–ç¼“å­˜çŠ¶æ€"""
    with _cache_lock:
        return {
            "cached_tickers": list(_data_cache.keys()),
            "cache_size": len(_data_cache),
            "oldest_data_age": min([time.time() - data.fetch_timestamp for data in _data_cache.values()]) if _data_cache else 0
        }

if __name__ == "__main__":
    # æ¼”ç¤ºç”¨æ³•
    print("=== YFinance Data Fetcher Demo ===")
    
    # è·å–å•ä¸ªè‚¡ç¥¨æ•°æ®
    try:
        data = get_yfinance_data("AAPL")
        print(f"âœ… Fetched data for AAPL")
        print(f"   Market Cap: {data.info.get('marketCap', 'N/A')}")
        print(f"   Data age: {time.time() - data.fetch_timestamp:.1f} seconds")
    except Exception as e:
        print(f"âŒ Error: {e}")
    
    # æ˜¾ç¤ºç¼“å­˜çŠ¶æ€
    cache_status = get_cache_status()
    print(f"\nCache status: {cache_status}") 